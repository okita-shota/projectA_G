{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okita-shota/projectA_G/blob/main/YOLOv8_HumanPoseEstimation_%E3%81%AE10_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCDyng5FwCGO"
      },
      "source": [
        "# YOLOで人体姿勢推定\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zF2f7ZGmIo3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y00. セットアップ"
      ],
      "metadata": {
        "id": "bjdNux7D6CFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WMDqk377sRqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa16524-41e7-490a-82f9-0af45f14ecdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 26 09:39:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU9caVYlqm6e"
      },
      "source": [
        "## Y01. YOLOv8をインストール\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 YOLOv8をダウンロード\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "o0SSdLJwxIMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 必要なライブラリのインストール\n",
        "import csv\n",
        "import cv2\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "gZnHMnaN7JRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 学習モデルの読み込み。姿勢推論用のモデルデータを読み込む\n",
        "model = YOLO(\"yolov8n-pose.pt\")"
      ],
      "metadata": {
        "id": "JSfBs3yL7P4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 keypointの位置毎の名称定義\n",
        "KEYPOINTS_NAMES = [\n",
        "    \"nose\", \"eye(L)\", \"eye(R)\", \"ear(L)\", \"ear(R)\",\n",
        "    \"shoulder(L)\", \"shoulder(R)\", \"elbow(L)\", \"elbow(R)\",\n",
        "    \"wrist(L)\", \"wrist(R)\", \"hip(L)\", \"hip(R)\",\n",
        "    \"knee(L)\", \"knee(R)\", \"ankle(L)\", \"ankle(R)\"\n",
        "]"
      ],
      "metadata": {
        "id": "6TfiLevr7SnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 ビデオライターの設定\n",
        "def setup_video_writer(capture, output_path):\n",
        "    \"\"\"ビデオライターの設定\"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    return cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
      ],
      "metadata": {
        "id": "dG0WE7kM73dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 姿勢情報をCSVファイルに書き出す\n",
        "def write_pose_to_csv(csv_path, frame_count, keypoints, confs):\n",
        "    \"\"\"姿勢情報をCSVファイルに書き出す\"\"\"\n",
        "    row = [frame_count]\n",
        "    for index, keypoint in enumerate(zip(keypoints, confs)):\n",
        "        x, y = int(keypoint[0][0]), int(keypoint[0][1])\n",
        "        score = keypoint[1]\n",
        "        row.extend([x, y, score])\n",
        "    with open(csv_path, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "3UN92Q7b8NoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 フレームにキーポイントと骨格を描画する\n",
        "def draw_keypoints(frame, keypoints, confs):\n",
        "    \"\"\"フレームにキーポイントと骨格を描画する\"\"\"\n",
        "    for index, keypoint in enumerate(zip(keypoints, confs)):\n",
        "        x, y = int(keypoint[0][0]), int(keypoint[0][1])\n",
        "        score = keypoint[1]\n",
        "        if score >= 0.5:\n",
        "            cv2.circle(frame, (x, y), 5, (255, 0, 255), -1)\n",
        "            cv2.putText(frame, KEYPOINTS_NAMES[index], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1, cv2.LINE_AA)\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "2L_xqf5M8QRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 動画をフレームごとに処理し、姿勢情報を取得してCSVと動画に保存する\n",
        "def process_video(input_video_path, output_video_path, csv_path):\n",
        "    \"\"\"動画をフレームごとに処理し、姿勢情報を取得してCSVと動画に保存する\"\"\"\n",
        "    capture = cv2.VideoCapture(input_video_path)\n",
        "    video_writer = setup_video_writer(capture, output_video_path)\n",
        "\n",
        "    with open(csv_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # ヘッダー行を書き込む\n",
        "        header = [\"frame\"]\n",
        "        for name in KEYPOINTS_NAMES:\n",
        "            header.extend([f\"{name}_x\", f\"{name}_y\", f\"{name}_score\"])\n",
        "        writer.writerow(header)\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while capture.isOpened():\n",
        "        success, frame = capture.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # 推論を実行\n",
        "        results = model(frame)\n",
        "\n",
        "        if len(results[0].keypoints) > 0:\n",
        "            keypoints = results[0].keypoints\n",
        "            confs = keypoints.conf[0].tolist()  # 推論結果:1に近いほど信頼度が高い\n",
        "            xys = keypoints.xy[0].tolist()  # 座標\n",
        "\n",
        "            # 姿勢情報をCSVファイルに書き出す\n",
        "            write_pose_to_csv(csv_path, frame_count, xys, confs)\n",
        "            # キーポイントと骨格をフレームに描画する\n",
        "            frame = draw_keypoints(frame, xys, confs)\n",
        "\n",
        "        # フレームに骨格情報を描画したものを動画に書き出す\n",
        "        video_writer.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    capture.release()\n",
        "    video_writer.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "DxFA_jLM8Sbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y02. サンプル動画（sample.mp4）の読み込み"
      ],
      "metadata": {
        "id": "yPGAi7FX2qwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y02.1　（一番簡単）\n",
        "# ファイルをドラッグ＆ドロップ '/content/sample.mp4'\n",
        "\n",
        "# Y02-.2\n",
        "# 解析用動画のアップロード（無料アカウントの場合はエラー）\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Vut9AZ818-D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y03. サンプル動画（sample.mp4）の骨格情報の推定"
      ],
      "metadata": {
        "id": "PbQKLRMC9Jki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.1 （今回は）fpsを30で統一する"
      ],
      "metadata": {
        "id": "PlqkkyaJ79Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.1 今回はfpsを30で統一する\n",
        "\n",
        "# ドラッグ&ドロップの場合\n",
        "# !ffmpeg -y -i \"sample.mp4\" -vf \"fps=30\" \"sample_30fps.mp4\"\n",
        "\n",
        "# # Google Driveの場合\n",
        "!ffmpeg -y -i \"/content/drive/MyDrive/20240903_video/sample.mp4\" -vf \"fps=30\" \"sample_30fps.mp4\""
      ],
      "metadata": {
        "id": "V-_PFE5Vz9kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.2 動画のwidth/height/fpsを取得"
      ],
      "metadata": {
        "id": "N5RQ_xUe8C6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.2 動画のwidth/height/fpsを取得\n",
        "import cv2\n",
        "\n",
        "# ドラッグ&ドロップの場合\n",
        "# video_path = \"sample.mp4\"\n",
        "\n",
        "# # Google Driveの場合\n",
        "video_path = \"/content/drive/MyDrive/20240903_video/sample.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"sample.mp4\")\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "video_path = \"sample_30fps.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"\")\n",
        "print(\"sample_30fps.mp4\")\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))"
      ],
      "metadata": {
        "id": "iNJT5egu19Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.3 入力動画のパスと出力ファイルのパスを指定"
      ],
      "metadata": {
        "id": "Xo2kNQcv8IeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.3 入力動画のパスと出力ファイルのパスを指定\n",
        "input_video_path = '/content/sample_30fps.mp4'\n",
        "output_video_path = 'sample_30fps_with_pose.mp4'\n",
        "csv_path = 'sample_30fps_pose_keypoints.csv'"
      ],
      "metadata": {
        "id": "TL0DfTqO0xDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.4 動画を処理し、姿勢情報を取得してCSVと動画に保存"
      ],
      "metadata": {
        "id": "LHTOcYnE8Q2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.4 動画を処理し、姿勢情報を取得してCSVと動画に保存\n",
        "process_video(input_video_path, output_video_path, csv_path)"
      ],
      "metadata": {
        "id": "NAc3TM2V0yvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.5 結果確認用動画の作成"
      ],
      "metadata": {
        "id": "OanfBW2V8T32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.5 結果確認用動画の作成\n",
        "!ffmpeg -y -i {output_video_path} -vf scale=600:-2 {\"sample_30fps_with_pose.mov\"}"
      ],
      "metadata": {
        "id": "wPHTcJO48WLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y03.6 動画の再生"
      ],
      "metadata": {
        "id": "2753ld_48XfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y03.6 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open( \"sample_30fps_with_pose.mov\", 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")\n"
      ],
      "metadata": {
        "id": "qgVM-zAV75Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y04. 比較用動画（f0.mp4）の読み込み"
      ],
      "metadata": {
        "id": "3pm6Jn8CZXJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y04.1\n",
        "# ドラッグ＆ドロップ '/content/f0.mp4'\n",
        "\n",
        "# Y04.2\n",
        "# 解析したい動画のアップロード （無料アカウントの場合はエラー）\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "s7xGViJ4eTLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y05. 比較用動画（f0.mp4）の骨格情報の推定"
      ],
      "metadata": {
        "id": "UeQNZCjh24_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.1 （今回は）fpsを30で統一する"
      ],
      "metadata": {
        "id": "Ui_-gysF8eh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.1 今回はfpsを30で統一する\n",
        "# sample.mp4を変換した時と比べて、どこが変更されているか要確認。 答え：ファイル名だけです。\n",
        "# ドラッグ&ドロップの場合\n",
        "# !ffmpeg -y -i \"f0.mp4\" -vf \"fps=30\" \"f0_30fps.mp4\"\n",
        "\n",
        "# # Google Driveの場合\n",
        "!ffmpeg -y -i \"/content/drive/MyDrive/20240903_video/f0.mp4\" -vf \"fps=30\" \"f0_30fps.mp4\""
      ],
      "metadata": {
        "id": "tXvicZm8ZegN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.2 動画のwidth/height/fpsを取得"
      ],
      "metadata": {
        "id": "ZbQ6aqCY8i__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.2 動画のwidth/height/fpsを取得\n",
        "import cv2\n",
        "\n",
        "# # ドラッグ&ドロップの場合\n",
        "# video_path = \"f0.mp4\"\n",
        "# # Google Driveの場合\n",
        "video_path = \"/content/drive/MyDrive/20240903_video/f0.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"f0.mp4\")\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "video_path = \"f0_30fps.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"\")\n",
        "print(\"f0_30fps.mp4\")\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))"
      ],
      "metadata": {
        "id": "G37KLu1k6CPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.3 入力動画のパスと出力ファイルのパスを指定"
      ],
      "metadata": {
        "id": "KK5Bte-B8mI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.3 入力動画のパスと出力ファイルのパスを指定\n",
        "input_video_path = '/content/f0_30fps.mp4'\n",
        "output_video_path = 'f0_30fps_with_pose.mp4'\n",
        "csv_path = 'f0_30fps_pose_keypoints.csv'"
      ],
      "metadata": {
        "id": "FRtM6An23L8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.4 動画を処理し、姿勢情報を取得してCSVと動画に保存"
      ],
      "metadata": {
        "id": "_vyaNLDi83S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.4 動画を処理し、姿勢情報を取得してCSVと動画に保存\n",
        "process_video(input_video_path, output_video_path, csv_path)"
      ],
      "metadata": {
        "id": "VibjW1z0zJxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.5 結果確認用動画の作成"
      ],
      "metadata": {
        "id": "Q5E2dxqX86bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.5 結果確認用動画の作成\n",
        "!ffmpeg -y -i {output_video_path} -vf scale=600:-2 {\"f0_30fps_with_pose.mov\"}"
      ],
      "metadata": {
        "id": "l5EtDd623Szz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.6 動画の再生"
      ],
      "metadata": {
        "id": "5U4Z5DLJ89RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y05.6 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open( \"f0_30fps_with_pose.mov\", 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")\n"
      ],
      "metadata": {
        "id": "NGXyZ4okAGie",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y05.7 他の動画（f1.mp4）でも適用してみよう"
      ],
      "metadata": {
        "id": "UmDhSMGiH684"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y05.7.1\n",
        "# f1.mp4をアップロードしよう"
      ],
      "metadata": {
        "id": "P94QCg7WIS9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y05.7.2\n",
        "# 簡単にするためにファイル名と拡張子を最初に定義\n",
        "file_name = \"f1\"\n",
        "extension = \".mp4\"\n",
        "\n",
        "### Y05.1 今回はfpsを30で統一する\n",
        "# # ドラッグ&ドロップの場合\n",
        "# !ffmpeg -y -i {file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "# # Google Driveの場合\n",
        "!ffmpeg -y -i \"/content/drive/MyDrive/20240903_video/\"{file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "\n",
        "### Y05.2 動画のwidth/height/fpsを取得\n",
        "import cv2\n",
        "\n",
        "video_path = file_name+extension\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(file_name+extension)\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "video_path = file_name+\"_30fps.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "print(\"\")\n",
        "print(file_name+\"_30fps.mp4\")\n",
        "print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "### Y05.3 入力動画のパスと出力ファイルのパスを指定\n",
        "input_video_path = \"/content/\"+file_name+\"_30fps.mp4\"\n",
        "output_video_path = file_name+\"_30fps_with_pose.mp4\"\n",
        "csv_path = file_name+\"_30fps_pose_keypoints.csv\"\n",
        "\n",
        "### Y05.4 動画を処理し、姿勢情報を取得してCSVと動画に保存\n",
        "process_video(input_video_path, output_video_path, csv_path)\n",
        "\n",
        "### Y05.5 結果確認用動画の作成\n",
        "!ffmpeg -y -i {output_video_path} -vf scale=600:-2 {file_name}_30fps_with_pose.mov\n",
        "\n",
        "### Y05.6 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open( file_name+\"_30fps_with_pose.mov\", 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "N3I5QOHuIEnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y05.7.3\n",
        "# 関数として定義しておく\n",
        "\n",
        "def get_pose(file_name:str, extension:str):\n",
        "  ### Y05.1 今回はfpsを30で統一する\n",
        "  # # ドラッグ&ドロップの場合\n",
        "  # !ffmpeg -y -i {file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "  # # Google Driveの場合\n",
        "  !ffmpeg -y -i \"/content/drive/MyDrive/20240903_video/\"{file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "\n",
        "  ### Y05.2 動画のwidth/height/fpsを取得\n",
        "  import cv2\n",
        "\n",
        "  video_path = file_name+extension\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  print(file_name+extension)\n",
        "  print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "  video_path = file_name+\"_30fps.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  print(\"\")\n",
        "  print(file_name+\"_30fps.mp4\")\n",
        "  print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "  ### Y05.3 入力動画のパスと出力ファイルのパスを指定\n",
        "  input_video_path = \"/content/\"+file_name+\"_30fps.mp4\"\n",
        "  output_video_path = file_name+\"_30fps_with_pose.mp4\"\n",
        "  csv_path = file_name+\"_30fps_pose_keypoints.csv\"\n",
        "\n",
        "  ### Y05.4 動画を処理し、姿勢情報を取得してCSVと動画に保存\n",
        "  process_video(input_video_path, output_video_path, csv_path)\n",
        "\n",
        "  ### Y05.5 結果確認用動画の作成\n",
        "  !ffmpeg -y -i {output_video_path} -vf scale=600:-2 {file_name}_30fps_with_pose.mov\n",
        "\n",
        "  ### Y05.6 動画の再生\n",
        "  from IPython.display import HTML\n",
        "  from base64 import b64encode\n",
        "\n",
        "  mp4 = open( file_name+\"_30fps_with_pose.mov\", 'rb').read()\n",
        "  data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "  HTML(f\"\"\"\n",
        "  <video width=\"50%\" height=\"50%\" controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  </video>\"\"\")"
      ],
      "metadata": {
        "id": "ndemouvCKtCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y05.7.4\n",
        "# f2.mp4をアップロードしてみよう"
      ],
      "metadata": {
        "id": "jaTle1z6LA7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y05.7.5\n",
        "# これ以降はこの関数を呼び出すだけで、骨格推定が実行できる\n",
        "get_pose(\"f2\", \".mp4\")"
      ],
      "metadata": {
        "id": "WK61DSlmLCm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y06. 単位ベクトルに変換"
      ],
      "metadata": {
        "id": "b3Z4n156z0_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.1 骨格情報が入ったcsvファイルの中身を確認"
      ],
      "metadata": {
        "id": "CDb65rmW9Eak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y06.1 骨格情報が入ったcsvファイルの中身を確認\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(\"sample_30fps_pose_keypoints.csv\").head()"
      ],
      "metadata": {
        "id": "ee3xVzTkwjor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.2 0フレーム目を可視化\n"
      ],
      "metadata": {
        "id": "oMxFWfG_9Kp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y06.2 0フレーム目を可視化\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_zero_frame(file_path:str):\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  # 0フレームのデータをフィルタリングする\n",
        "  frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "  # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "  keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "  # 0フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "  x_coords = frame_0_data.iloc[0, 1::3]\n",
        "  y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "  # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "  keypoints = {\n",
        "      'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "      'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "      'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "      'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "  }\n",
        "\n",
        "  connections = [\n",
        "      ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "      ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "      ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "      ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "      ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "      ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "  ]\n",
        "\n",
        "  # y軸を反転させた状態で0フレームの散布図をプロットする\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # キーポイントをプロット\n",
        "  plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "  # 各キーポイントの横に名前をプロットする\n",
        "  for i, name in enumerate(keypoint_names):\n",
        "      plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "  # キーポイントを矢印で接続\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "  plt.xlabel('X Coordinates')\n",
        "  plt.ylabel('Y Coordinates')\n",
        "  plt.title('Scatter Plot of Keypoints for Frame 0')\n",
        "  plt.grid(True)\n",
        "  plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "  plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "DM68iuLk4urG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_zero_frame('sample_30fps_pose_keypoints.csv')"
      ],
      "metadata": {
        "id": "xz2BKg7NP2Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.3 0フレーム目を単位ベクトルに変換（可視化確認用）"
      ],
      "metadata": {
        "id": "q8WtTGPV_BgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_zero_frame_norm(file_path:str):\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  # 0フレームのデータをフィルタリングする\n",
        "  frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "  # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "  keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "  # 0フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "  x_coords = frame_0_data.iloc[0, 1::3]\n",
        "  y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "  # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "  keypoints = {\n",
        "      'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "      'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "      'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "      'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "  }\n",
        "\n",
        "  connections = [\n",
        "      # ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "      ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "      ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "      ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "      ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "      ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "  ]\n",
        "\n",
        "  # y軸を反転させた状態で0フレームの散布図をプロットする\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # キーポイントをプロット\n",
        "  plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "  # 各キーポイントの横に名前をプロットする\n",
        "  for i, name in enumerate(keypoint_names):\n",
        "      plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "  # キーポイントを矢印で接続\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "  # 単位ベクトルを計算する\n",
        "  unit_vectors = []\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      norm = np.sqrt(dx**2 + dy**2)\n",
        "      if norm != 0:\n",
        "          unit_vectors.append((dx / norm, dy / norm, x1, y1))\n",
        "\n",
        "  # 単位ベクトルをプロットする\n",
        "  for uv in unit_vectors:\n",
        "      plt.arrow(uv[2], uv[3], uv[0] * 100, uv[1] * 100, head_width=5, head_length=10, fc='red', ec='red', length_includes_head=True)\n",
        "\n",
        "  plt.xlabel('X Coordinates')\n",
        "  plt.ylabel('Y Coordinates')\n",
        "  plt.title('Visualization of Unit Vectors for Frame 0')\n",
        "  plt.grid(True)\n",
        "  plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "  plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "EK7PHHjV_BQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_zero_frame_norm( 'sample_30fps_pose_keypoints.csv')"
      ],
      "metadata": {
        "id": "ZSELWTbBQPlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.4 全てのフレームを単位ベクトルに変換してcsvファイルに格納"
      ],
      "metadata": {
        "id": "otxo176T_oBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y06.4 全てのフレームを単位ベクトルに変換してcsvファイルに格納\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 単位ベクトルを計算し、結果を連結する関数を定義\n",
        "def calc_and_concat_norms(cols, data):\n",
        "    unit_vectors_list = []\n",
        "    for col1, col2 in cols:\n",
        "        # 各点のconfidenceを取得\n",
        "        confidence_col1 = data[f'{col1}_score'].values\n",
        "        confidence_col2 = data[f'{col2}_score'].values\n",
        "\n",
        "        # ベクトルの差分を計算し、confidenceが0.1以下の場合は差分を0に設定\n",
        "        vector_diff = np.where((confidence_col1 > 0.1)[:, None] & (confidence_col2 > 0.1)[:, None],\n",
        "                               data[[f'{col2}_x', f'{col2}_y']].values - data[[f'{col1}_x', f'{col1}_y']].values,\n",
        "                               np.array([0, 0]))\n",
        "\n",
        "        # 単位ベクトルを計算\n",
        "        norm_diff = np.linalg.norm(vector_diff, axis=1, keepdims=True)\n",
        "        unit_vector_diff = np.where(norm_diff != 0, vector_diff / norm_diff, np.array([0, 0]))\n",
        "\n",
        "        # 結果をデータフレームに変換\n",
        "        unit_vectors_df = pd.DataFrame({\n",
        "            f'unit_x_{col1}_{col2}': unit_vector_diff[:, 0],\n",
        "            f'unit_y_{col1}_{col2}': unit_vector_diff[:, 1]\n",
        "        })\n",
        "\n",
        "        # 各ペアの結果をリストに追加\n",
        "        unit_vectors_list.append(unit_vectors_df)\n",
        "\n",
        "    # 全てのデータフレームを列方向に連結\n",
        "    final_df = pd.concat(unit_vectors_list, axis=1)\n",
        "    return final_df\n",
        "\n",
        "# 指定されたディレクトリ内のファイルを処理する関数を定義\n",
        "def transform_to_norm(filename: str):\n",
        "    # ファイルパスを設定\n",
        "    file_path = f\"{filename}_30fps_pose_keypoints.csv\"\n",
        "    output_file_path = f\"{filename}_30fps_pose_keypoints_norm.csv\"\n",
        "\n",
        "    # CSVファイルを読み込む\n",
        "    data = pd.read_csv(file_path).fillna(0)\n",
        "\n",
        "    # 対象の点のペアを定義（0フレーム目の可視化に基づく）\n",
        "    points_pairs = [\n",
        "        # ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "        ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "        ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "        ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "        ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "        ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "    ]\n",
        "\n",
        "    # 単位ベクトルを計算し連結\n",
        "    result_df = calc_and_concat_norms(points_pairs, data)\n",
        "\n",
        "    # 結果をCSVファイルに保存\n",
        "    result_df.to_csv(output_file_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "QzN9D2Mx_n1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定されたディレクトリで関数を実行\n",
        "transform_to_norm(\"sample\")\n",
        "transform_to_norm(\"f0\")\n",
        "transform_to_norm(\"f1\")\n",
        "transform_to_norm(\"f2\")"
      ],
      "metadata": {
        "id": "NTQjVn66KAer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.5 変換結果のcsvファイルの中身を確認"
      ],
      "metadata": {
        "id": "bCDghgWxB7pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y06.5 変換結果のcsvファイルの中身を確認\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(\"sample_30fps_pose_keypoints_norm.csv\").head()"
      ],
      "metadata": {
        "id": "nZ_lzwxzB7fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y06.5 変換結果の可視化"
      ],
      "metadata": {
        "id": "1UciqeEMBJbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y06.5 変換結果の可視化\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "def visualize_norms(file_name: str):\n",
        "    # CSVファイルを読み込む\n",
        "    file_path = file_name + '_30fps_pose_keypoints.csv'\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # 単位ベクトルが計算された結果のCSVファイルを読み込む\n",
        "    norm_file_path = file_name + '_30fps_pose_keypoints_norm.csv'\n",
        "    norm_data = pd.read_csv(norm_file_path)\n",
        "\n",
        "    # フレーム数を取得\n",
        "    num_frames = norm_data.shape[0]\n",
        "\n",
        "    # カラーマップを設定（半透明にする）\n",
        "    colors = cm.viridis(np.linspace(0, 1, num_frames))\n",
        "    colors[:, 3] = 0.2  # アルファ値を設定（0.5にする）\n",
        "\n",
        "    # 初期フレームのデータをフィルタリングする\n",
        "    frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "    # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "    keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "    # 初期フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "    x_coords = frame_0_data.iloc[0, 1::3]\n",
        "    y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "    # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "    keypoints = {\n",
        "        'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "        'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "        'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "        'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "    }\n",
        "\n",
        "    connections = [\n",
        "        ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "        ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "        ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "        ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "        ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "    ]\n",
        "\n",
        "    # y軸を反転させた状態で初期フレームの散布図をプロットする\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # 初期フレームのキーポイントをプロット\n",
        "    plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "    # 各キーポイントの横に名前をプロットする\n",
        "    for i, name in enumerate(keypoint_names):\n",
        "        plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "    # 初期フレームのキーポイントを矢印で接続\n",
        "    for connection in connections:\n",
        "        x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "        x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "        dx, dy = x2 - x1, y2 - y1\n",
        "        plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "    # 単位ベクトルをプロットする\n",
        "    for connection in connections:\n",
        "        unit_x_col = f'unit_x_{connection[0]}_{connection[1]}'\n",
        "        unit_y_col = f'unit_y_{connection[0]}_{connection[1]}'\n",
        "        if unit_x_col in norm_data.columns and unit_y_col in norm_data.columns:\n",
        "            for i in range(num_frames):\n",
        "                x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "                unit_x, unit_y = norm_data.iloc[i][unit_x_col], norm_data.iloc[i][unit_y_col]\n",
        "                plt.arrow(x1, y1, unit_x * 100, unit_y * 100, head_width=5, head_length=10, fc=colors[i], ec=colors[i], length_includes_head=True)\n",
        "\n",
        "    plt.xlabel('X Coordinates')\n",
        "    plt.ylabel('Y Coordinates')\n",
        "    plt.title('Visualization of Unit Vectors Over Time')\n",
        "    plt.grid(True)\n",
        "    plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "    plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0YrLpS0M-GBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_norms(\"sample\")"
      ],
      "metadata": {
        "id": "yqidcAK5PeZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Y07. 動的時間伸縮法 / DTW (Dynamic Time Warping) を計算"
      ],
      "metadata": {
        "id": "H0rCZzAMFuFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.gyazo.com/7cd1e5f76b8dd0f8db21792cfd09f517.gif\" alt=\"GIF Image\">\n"
      ],
      "metadata": {
        "id": "epPwbBwRGAy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y07.1 ライブラリをインストール\n",
        "!pip install fastdtw"
      ],
      "metadata": {
        "id": "FIe7OW0wAeSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Y07.2 DTWの計算\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "def calc_dtw(a, b):\n",
        "  x = np.array(pd.read_csv(a).fillna(0))\n",
        "  y = np.array(pd.read_csv(b).fillna(0))\n",
        "  distance, path = fastdtw(x, y, dist=euclidean)\n",
        "  print(a, b, distance)\n",
        " # return distance\n",
        "calc_dtw(\"sample_30fps_pose_keypoints_norm.csv\",\"f0_30fps_pose_keypoints_norm.csv\")\n",
        "calc_dtw(\"sample_30fps_pose_keypoints_norm.csv\",\"f1_30fps_pose_keypoints_norm.csv\")\n",
        "calc_dtw(\"sample_30fps_pose_keypoints_norm.csv\",\"f2_30fps_pose_keypoints_norm.csv\")"
      ],
      "metadata": {
        "id": "-kW3N0o9AeO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DTWは時間軸方向を圧縮しているため、リズムに合わせるなどは無視してしまっている点に注意！"
      ],
      "metadata": {
        "id": "6Mj1o41PG0tZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Y08. 二乗平均平方根誤差 / RMSE(Root Mean Squared Error)を計算する"
      ],
      "metadata": {
        "id": "kpYwv0LCGlcZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://tsuchidalab.jp/wp1/wp-content/uploads/2024/05/1000.png\" alt=\"Image\">\n"
      ],
      "metadata": {
        "id": "qwRRA0DCG23g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Y08.2 Root Mean Squared Error(RMSE)の計算\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calc_rmse(a, b):\n",
        "  x = pd.read_csv(a).fillna(0)\n",
        "  y = pd.read_csv(b).fillna(0)[:len(x)] #元動画の長さに合わせる\n",
        "  rmse = np.sqrt(mean_squared_error(x, y))\n",
        "  print(a, b,'{:.3f}'.format(rmse))\n",
        "\n",
        "calc_rmse(\"sample_30fps_pose_keypoints_norm.csv\",\"f0_30fps_pose_keypoints_norm.csv\")\n",
        "calc_rmse(\"sample_30fps_pose_keypoints_norm.csv\",\"f1_30fps_pose_keypoints_norm.csv\")\n",
        "calc_rmse(\"sample_30fps_pose_keypoints_norm.csv\",\"f2_30fps_pose_keypoints_norm.csv\")"
      ],
      "metadata": {
        "id": "yq1E__vDGmgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "厳密にチェックしているけど、ちょっとでもリズムを取るタイミングがズレると、動きが似ていても大きな値を取ってしまう"
      ],
      "metadata": {
        "id": "J3XkP585G6NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Y09 オリジナル動画を読み込んでみよう"
      ],
      "metadata": {
        "id": "NOq6LK2DQbjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## オリジナル一つ目の動画をアップロード"
      ],
      "metadata": {
        "id": "QQud3_0nTcjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 動画の長さは以下のコマンドを使って適宜編集しよう\n",
        "# スマホ上で編集するのが一番楽だとは思います（注：研究評価など厳密なスコアを算出する際には楽曲ベースで正確に切り出すこと）\n",
        "# 動画の縦横は気にしなくて良いです\n",
        "\n",
        "uploadfile = \"test.mov\"\n",
        "# 開始10秒後から30秒間の動画を切り出したい場合、次のようにコマンドを入力\n",
        "# !ffmpeg -ss 10 -i {uploadfile} -t 30 -c copy test.mp4"
      ],
      "metadata": {
        "id": "vY-SGE4oSjO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 動画は\"/content/drive/MyDrive/20240903_video/\" にアップロードすること。じゃないと動きません（パスの話）\n",
        "\n",
        "### 骨格推定の適用\n",
        "fname = \"test\" # ここの名前をアップロードした名前で。楽なのはこれに合わせてtestという名前の動画にしておく。\n",
        "\n",
        "# ファイル名は適宜アップロードした内容と合わせること\n",
        "get_pose(fname, \".mp4\") # ここの拡張子もアップロードした名前で。iPhoneならMOVになると思います。\n",
        "\n",
        "### 推定結果の確認\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(fname + \"_30fps_pose_keypoints.csv\").head()\n",
        "\n",
        "# ゼロフレーム目の可視化\n",
        "visualize_zero_frame(fname + '_30fps_pose_keypoints.csv')\n",
        "\n",
        "# ゼロフレーム目の単位ベクトルの可視化\n",
        "visualize_zero_frame_norm(fname + '_30fps_pose_keypoints.csv')\n",
        "\n",
        "# 単位ベクトル作成\n",
        "transform_to_norm(fname)\n",
        "\n",
        "# 単位ベクトルの可視化\n",
        "visualize_norms(fname)"
      ],
      "metadata": {
        "id": "vO87mCeZP8fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 課題動画"
      ],
      "metadata": {
        "id": "BjniaZf7TYmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 骨格推定の適用\n",
        "fname = \"mihon\"\n",
        "\n",
        "# ファイル名は適宜アップロードした内容と合わせること\n",
        "get_pose(fname, \".mp4\")\n",
        "\n",
        "### 推定結果の確認\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(fname + \"_30fps_pose_keypoints.csv\").head()\n",
        "\n",
        "# ゼロフレーム目の可視化\n",
        "visualize_zero_frame(fname + '_30fps_pose_keypoints.csv')\n",
        "\n",
        "# ゼロフレーム目の単位ベクトルの可視化\n",
        "visualize_zero_frame_norm(fname + '_30fps_pose_keypoints.csv')\n",
        "\n",
        "# 単位ベクトル作成\n",
        "transform_to_norm(fname)\n",
        "\n",
        "# 単位ベクトルの可視化\n",
        "visualize_norms(fname)"
      ],
      "metadata": {
        "id": "a9b7vq_NP8cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DTWコスト計算"
      ],
      "metadata": {
        "id": "dTBN4YGETgHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### DTWコスト計算\n",
        "\n",
        "calc_dtw(\"test_30fps_pose_keypoints_norm.csv\",\"mihon_30fps_pose_keypoints_norm.csv\")"
      ],
      "metadata": {
        "id": "FO6jVJ55RJU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oXjouxgmNCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ds17rbS3mMy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 以下はdef関連のエラーが出た人用。以下のコードを実行後に上の課題用コードに戻ってください。"
      ],
      "metadata": {
        "id": "3qWJVl6KmNvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 YOLOv8をダウンロード\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "# 2 必要なライブラリのインストール\n",
        "import csv\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# 3 学習モデルの読み込み。姿勢推論用のモデルデータを読み込む\n",
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "# 4 keypointの位置毎の名称定義\n",
        "KEYPOINTS_NAMES = [\n",
        "    \"nose\", \"eye(L)\", \"eye(R)\", \"ear(L)\", \"ear(R)\",\n",
        "    \"shoulder(L)\", \"shoulder(R)\", \"elbow(L)\", \"elbow(R)\",\n",
        "    \"wrist(L)\", \"wrist(R)\", \"hip(L)\", \"hip(R)\",\n",
        "    \"knee(L)\", \"knee(R)\", \"ankle(L)\", \"ankle(R)\"\n",
        "]\n",
        "\n",
        "# 5 ビデオライターの設定\n",
        "def setup_video_writer(capture, output_path):\n",
        "    \"\"\"ビデオライターの設定\"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    return cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# 6 姿勢情報をCSVファイルに書き出す\n",
        "def write_pose_to_csv(csv_path, frame_count, keypoints, confs):\n",
        "    \"\"\"姿勢情報をCSVファイルに書き出す\"\"\"\n",
        "    row = [frame_count]\n",
        "    for index, keypoint in enumerate(zip(keypoints, confs)):\n",
        "        x, y = int(keypoint[0][0]), int(keypoint[0][1])\n",
        "        score = keypoint[1]\n",
        "        row.extend([x, y, score])\n",
        "    with open(csv_path, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(row)\n",
        "\n",
        "# 7 フレームにキーポイントと骨格を描画する\n",
        "def draw_keypoints(frame, keypoints, confs):\n",
        "    \"\"\"フレームにキーポイントと骨格を描画する\"\"\"\n",
        "    for index, keypoint in enumerate(zip(keypoints, confs)):\n",
        "        x, y = int(keypoint[0][0]), int(keypoint[0][1])\n",
        "        score = keypoint[1]\n",
        "        if score >= 0.5:\n",
        "            cv2.circle(frame, (x, y), 5, (255, 0, 255), -1)\n",
        "            cv2.putText(frame, KEYPOINTS_NAMES[index], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1, cv2.LINE_AA)\n",
        "    return frame\n",
        "\n",
        "# 8 動画をフレームごとに処理し、姿勢情報を取得してCSVと動画に保存する\n",
        "def process_video(input_video_path, output_video_path, csv_path):\n",
        "    \"\"\"動画をフレームごとに処理し、姿勢情報を取得してCSVと動画に保存する\"\"\"\n",
        "    capture = cv2.VideoCapture(input_video_path)\n",
        "    video_writer = setup_video_writer(capture, output_video_path)\n",
        "\n",
        "    with open(csv_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # ヘッダー行を書き込む\n",
        "        header = [\"frame\"]\n",
        "        for name in KEYPOINTS_NAMES:\n",
        "            header.extend([f\"{name}_x\", f\"{name}_y\", f\"{name}_score\"])\n",
        "        writer.writerow(header)\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while capture.isOpened():\n",
        "        success, frame = capture.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # 推論を実行\n",
        "        results = model(frame)\n",
        "\n",
        "        if len(results[0].keypoints) > 0:\n",
        "            keypoints = results[0].keypoints\n",
        "            confs = keypoints.conf[0].tolist()  # 推論結果:1に近いほど信頼度が高い\n",
        "            xys = keypoints.xy[0].tolist()  # 座標\n",
        "\n",
        "            # 姿勢情報をCSVファイルに書き出す\n",
        "            write_pose_to_csv(csv_path, frame_count, xys, confs)\n",
        "            # キーポイントと骨格をフレームに描画する\n",
        "            frame = draw_keypoints(frame, xys, confs)\n",
        "\n",
        "        # フレームに骨格情報を描画したものを動画に書き出す\n",
        "        video_writer.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    capture.release()\n",
        "    video_writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Y05.7.3\n",
        "# 関数として定義しておく\n",
        "\n",
        "def get_pose(file_name:str, extension:str):\n",
        "  ### Y05.1 今回はfpsを30で統一する\n",
        "  # # ドラッグ&ドロップの場合\n",
        "  # !ffmpeg -y -i {file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "  # # Google Driveの場合\n",
        "  !ffmpeg -y -i \"/content/drive/MyDrive/20240903_video/\"{file_name}{extension} -vf \"fps=30\" {file_name}\"_30fps.mp4\"\n",
        "\n",
        "  ### Y05.2 動画のwidth/height/fpsを取得\n",
        "  import cv2\n",
        "\n",
        "  video_path = file_name+extension\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  print(file_name+extension)\n",
        "  print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "  video_path = file_name+\"_30fps.mp4\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "  height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  print(\"\")\n",
        "  print(file_name+\"_30fps.mp4\")\n",
        "  print(\"width:{}, height:{}, fps:{}\".format(width,height,fps))\n",
        "\n",
        "  ### Y05.3 入力動画のパスと出力ファイルのパスを指定\n",
        "  input_video_path = \"/content/\"+file_name+\"_30fps.mp4\"\n",
        "  output_video_path = file_name+\"_30fps_with_pose.mp4\"\n",
        "  csv_path = file_name+\"_30fps_pose_keypoints.csv\"\n",
        "\n",
        "  ### Y05.4 動画を処理し、姿勢情報を取得してCSVと動画に保存\n",
        "  process_video(input_video_path, output_video_path, csv_path)\n",
        "\n",
        "  ### Y05.5 結果確認用動画の作成\n",
        "  !ffmpeg -y -i {output_video_path} -vf scale=600:-2 {file_name}_30fps_with_pose.mov\n",
        "\n",
        "  ### Y05.6 動画の再生\n",
        "  from IPython.display import HTML\n",
        "  from base64 import b64encode\n",
        "\n",
        "  mp4 = open( file_name+\"_30fps_with_pose.mov\", 'rb').read()\n",
        "  data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "  HTML(f\"\"\"\n",
        "  <video width=\"50%\" height=\"50%\" controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  </video>\"\"\")\n",
        "\n",
        "### Y06.2 0フレーム目を可視化\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_zero_frame(file_path:str):\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  # 0フレームのデータをフィルタリングする\n",
        "  frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "  # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "  keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "  # 0フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "  x_coords = frame_0_data.iloc[0, 1::3]\n",
        "  y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "  # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "  keypoints = {\n",
        "      'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "      'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "      'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "      'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "  }\n",
        "\n",
        "  connections = [\n",
        "      ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "      ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "      ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "      ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "      ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "      ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "  ]\n",
        "\n",
        "  # y軸を反転させた状態で0フレームの散布図をプロットする\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # キーポイントをプロット\n",
        "  plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "  # 各キーポイントの横に名前をプロットする\n",
        "  for i, name in enumerate(keypoint_names):\n",
        "      plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "  # キーポイントを矢印で接続\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "  plt.xlabel('X Coordinates')\n",
        "  plt.ylabel('Y Coordinates')\n",
        "  plt.title('Scatter Plot of Keypoints for Frame 0')\n",
        "  plt.grid(True)\n",
        "  plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "  plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "  plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_zero_frame_norm(file_path:str):\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  # 0フレームのデータをフィルタリングする\n",
        "  frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "  # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "  keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "  # 0フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "  x_coords = frame_0_data.iloc[0, 1::3]\n",
        "  y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "  # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "  keypoints = {\n",
        "      'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "      'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "      'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "      'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "  }\n",
        "\n",
        "  connections = [\n",
        "      # ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "      ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "      ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "      ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "      ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "      ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "  ]\n",
        "\n",
        "  # y軸を反転させた状態で0フレームの散布図をプロットする\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # キーポイントをプロット\n",
        "  plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "  # 各キーポイントの横に名前をプロットする\n",
        "  for i, name in enumerate(keypoint_names):\n",
        "      plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "  # キーポイントを矢印で接続\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "  # 単位ベクトルを計算する\n",
        "  unit_vectors = []\n",
        "  for connection in connections:\n",
        "      x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "      x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "      dx, dy = x2 - x1, y2 - y1\n",
        "      norm = np.sqrt(dx**2 + dy**2)\n",
        "      if norm != 0:\n",
        "          unit_vectors.append((dx / norm, dy / norm, x1, y1))\n",
        "\n",
        "  # 単位ベクトルをプロットする\n",
        "  for uv in unit_vectors:\n",
        "      plt.arrow(uv[2], uv[3], uv[0] * 100, uv[1] * 100, head_width=5, head_length=10, fc='red', ec='red', length_includes_head=True)\n",
        "\n",
        "  plt.xlabel('X Coordinates')\n",
        "  plt.ylabel('Y Coordinates')\n",
        "  plt.title('Visualization of Unit Vectors for Frame 0')\n",
        "  plt.grid(True)\n",
        "  plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "  plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "  plt.show()\n",
        "\n",
        "### Y06.4 全てのフレームを単位ベクトルに変換してcsvファイルに格納\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 単位ベクトルを計算し、結果を連結する関数を定義\n",
        "def calc_and_concat_norms(cols, data):\n",
        "    unit_vectors_list = []\n",
        "    for col1, col2 in cols:\n",
        "        # 各点のconfidenceを取得\n",
        "        confidence_col1 = data[f'{col1}_score'].values\n",
        "        confidence_col2 = data[f'{col2}_score'].values\n",
        "\n",
        "        # ベクトルの差分を計算し、confidenceが0.1以下の場合は差分を0に設定\n",
        "        vector_diff = np.where((confidence_col1 > 0.1)[:, None] & (confidence_col2 > 0.1)[:, None],\n",
        "                               data[[f'{col2}_x', f'{col2}_y']].values - data[[f'{col1}_x', f'{col1}_y']].values,\n",
        "                               np.array([0, 0]))\n",
        "\n",
        "        # 単位ベクトルを計算\n",
        "        norm_diff = np.linalg.norm(vector_diff, axis=1, keepdims=True)\n",
        "        unit_vector_diff = np.where(norm_diff != 0, vector_diff / norm_diff, np.array([0, 0]))\n",
        "\n",
        "        # 結果をデータフレームに変換\n",
        "        unit_vectors_df = pd.DataFrame({\n",
        "            f'unit_x_{col1}_{col2}': unit_vector_diff[:, 0],\n",
        "            f'unit_y_{col1}_{col2}': unit_vector_diff[:, 1]\n",
        "        })\n",
        "\n",
        "        # 各ペアの結果をリストに追加\n",
        "        unit_vectors_list.append(unit_vectors_df)\n",
        "\n",
        "    # 全てのデータフレームを列方向に連結\n",
        "    final_df = pd.concat(unit_vectors_list, axis=1)\n",
        "    return final_df\n",
        "\n",
        "# 指定されたディレクトリ内のファイルを処理する関数を定義\n",
        "def transform_to_norm(filename: str):\n",
        "    # ファイルパスを設定\n",
        "    file_path = f\"{filename}_30fps_pose_keypoints.csv\"\n",
        "    output_file_path = f\"{filename}_30fps_pose_keypoints_norm.csv\"\n",
        "\n",
        "    # CSVファイルを読み込む\n",
        "    data = pd.read_csv(file_path).fillna(0)\n",
        "\n",
        "    # 対象の点のペアを定義（0フレーム目の可視化に基づく）\n",
        "    points_pairs = [\n",
        "        # ('nose', 'eye(L)'), ('nose', 'eye(R)'), ('eye(L)', 'ear(L)'), ('eye(R)', 'ear(R)'),\n",
        "        ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "        ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "        ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "        ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "        ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "    ]\n",
        "\n",
        "    # 単位ベクトルを計算し連結\n",
        "    result_df = calc_and_concat_norms(points_pairs, data)\n",
        "\n",
        "    # 結果をCSVファイルに保存\n",
        "    result_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "### Y06.5 変換結果の可視化\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "def visualize_norms(file_name: str):\n",
        "    # CSVファイルを読み込む\n",
        "    file_path = file_name + '_30fps_pose_keypoints.csv'\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # 単位ベクトルが計算された結果のCSVファイルを読み込む\n",
        "    norm_file_path = file_name + '_30fps_pose_keypoints_norm.csv'\n",
        "    norm_data = pd.read_csv(norm_file_path)\n",
        "\n",
        "    # フレーム数を取得\n",
        "    num_frames = norm_data.shape[0]\n",
        "\n",
        "    # カラーマップを設定（半透明にする）\n",
        "    colors = cm.viridis(np.linspace(0, 1, num_frames))\n",
        "    colors[:, 3] = 0.2  # アルファ値を設定（0.5にする）\n",
        "\n",
        "    # 初期フレームのデータをフィルタリングする\n",
        "    frame_0_data = data[data['frame'] == 0]\n",
        "\n",
        "    # キーポイントの名前のリスト（列名からスコアを除いたもの）\n",
        "    keypoint_names = [col.split('_')[0] for col in frame_0_data.columns[1::3]]\n",
        "\n",
        "    # 初期フレームのすべてのキーポイントのx座標とy座標を抽出する\n",
        "    x_coords = frame_0_data.iloc[0, 1::3]\n",
        "    y_coords = frame_0_data.iloc[0, 2::3]\n",
        "\n",
        "    # キーポイントの接続を定義（CSVのラベルに基づく）\n",
        "    keypoints = {\n",
        "        'nose': 0, 'eye(L)': 1, 'eye(R)': 2, 'ear(L)': 3, 'ear(R)': 4,\n",
        "        'shoulder(L)': 5, 'shoulder(R)': 6, 'elbow(L)': 7, 'elbow(R)': 8,\n",
        "        'wrist(L)': 9, 'wrist(R)': 10, 'hip(L)': 11, 'hip(R)': 12,\n",
        "        'knee(L)': 13, 'knee(R)': 14, 'ankle(L)': 15, 'ankle(R)': 16\n",
        "    }\n",
        "\n",
        "    connections = [\n",
        "        ('nose', 'shoulder(L)'), ('nose', 'shoulder(R)'), ('shoulder(L)', 'elbow(L)'),\n",
        "        ('shoulder(R)', 'elbow(R)'), ('elbow(L)', 'wrist(L)'), ('elbow(R)', 'wrist(R)'),\n",
        "        ('shoulder(L)', 'shoulder(R)'), ('shoulder(L)', 'hip(L)'), ('shoulder(R)', 'hip(R)'),\n",
        "        ('hip(L)', 'hip(R)'), ('hip(L)', 'knee(L)'), ('hip(R)', 'knee(R)'),\n",
        "        ('knee(L)', 'ankle(L)'), ('knee(R)', 'ankle(R)')\n",
        "    ]\n",
        "\n",
        "    # y軸を反転させた状態で初期フレームの散布図をプロットする\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # 初期フレームのキーポイントをプロット\n",
        "    plt.scatter(x_coords, y_coords, c='blue')\n",
        "\n",
        "    # 各キーポイントの横に名前をプロットする\n",
        "    for i, name in enumerate(keypoint_names):\n",
        "        plt.text(x_coords[i], y_coords[i], name, fontsize=9, ha='right')\n",
        "\n",
        "    # 初期フレームのキーポイントを矢印で接続\n",
        "    for connection in connections:\n",
        "        x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "        x2, y2 = x_coords[keypoints[connection[1]]], y_coords[keypoints[connection[1]]]\n",
        "        dx, dy = x2 - x1, y2 - y1\n",
        "        plt.arrow(x1, y1, dx, dy, head_width=15, head_length=25, fc='gray', ec='gray', length_includes_head=True)\n",
        "\n",
        "    # 単位ベクトルをプロットする\n",
        "    for connection in connections:\n",
        "        unit_x_col = f'unit_x_{connection[0]}_{connection[1]}'\n",
        "        unit_y_col = f'unit_y_{connection[0]}_{connection[1]}'\n",
        "        if unit_x_col in norm_data.columns and unit_y_col in norm_data.columns:\n",
        "            for i in range(num_frames):\n",
        "                x1, y1 = x_coords[keypoints[connection[0]]], y_coords[keypoints[connection[0]]]\n",
        "                unit_x, unit_y = norm_data.iloc[i][unit_x_col], norm_data.iloc[i][unit_y_col]\n",
        "                plt.arrow(x1, y1, unit_x * 100, unit_y * 100, head_width=5, head_length=10, fc=colors[i], ec=colors[i], length_includes_head=True)\n",
        "\n",
        "    plt.xlabel('X Coordinates')\n",
        "    plt.ylabel('Y Coordinates')\n",
        "    plt.title('Visualization of Unit Vectors Over Time')\n",
        "    plt.grid(True)\n",
        "    plt.gca().invert_yaxis()  # 原点を左上にするためにy軸を反転する\n",
        "    plt.axis('equal')  # 縦軸と横軸のスケールを同じにする\n",
        "    plt.show()\n",
        "\n",
        "### Y07.1 ライブラリをインストール\n",
        "!pip install fastdtw\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "\n",
        "def calc_dtw(a, b):\n",
        "  x = np.array(pd.read_csv(a).fillna(0))\n",
        "  y = np.array(pd.read_csv(b).fillna(0))\n",
        "  distance, path = fastdtw(x, y, dist=euclidean)\n",
        "  print(a, b, distance)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def calc_rmse(a, b):\n",
        "  x = pd.read_csv(a).fillna(0)\n",
        "  y = pd.read_csv(b).fillna(0)[:len(x)] #元動画の長さに合わせる\n",
        "  rmse = np.sqrt(mean_squared_error(x, y))\n",
        "  print(a, b,'{:.3f}'.format(rmse))"
      ],
      "metadata": {
        "id": "PBtH1jK-mQRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}